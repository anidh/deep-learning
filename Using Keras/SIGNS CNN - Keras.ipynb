{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version Is 1.12.0\n",
      "Open CV Version Is 3.4.4\n"
     ]
    }
   ],
   "source": [
    "#importing our libraries\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow Version Is \"+str(tf.__version__))\n",
    "import cv2\n",
    "print(\"Open CV Version Is \"+str(cv2.__version__))\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#Importing Keras and it's packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation,Conv2D,ZeroPadding2D,MaxPool2D,AveragePooling2D,BatchNormalization,InputLayer,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing The Respective Shapes\n",
      "The number of training examples are 1080\n",
      "The number of test examples are 120\n",
      "The shape of training X is (1080, 64, 64, 3)\n",
      "The shape of training Y is (1080,)\n",
      "The shape of testing X is (120, 64, 64, 3)\n",
      "The shape of testing Y is (120,)\n"
     ]
    }
   ],
   "source": [
    "#Let's do something about our dataset\n",
    "fileNameTrain=\"train_signs.h5\"\n",
    "fileNameTest=\"test_signs.h5\"\n",
    "fTrain=h5py.File(fileNameTrain,'r')\n",
    "fTest=h5py.File(fileNameTest,'r')\n",
    "X_train=fTrain[\"train_set_x\"].value\n",
    "Y_train=fTrain[\"train_set_y\"].value\n",
    "X_test=fTest[\"test_set_x\"].value\n",
    "Y_test=fTest[\"test_set_y\"].value\n",
    "print(\"Printing The Respective Shapes\")\n",
    "print(\"The number of training examples are {}\".format(X_train.shape[0]))\n",
    "print(\"The number of test examples are {}\".format(X_test.shape[0]))\n",
    "print(\"The shape of training X is {}\".format(X_train.shape))\n",
    "print(\"The shape of training Y is {}\".format(Y_train.shape))\n",
    "print(\"The shape of testing X is {}\".format(X_test.shape))\n",
    "print(\"The shape of testing Y is {}\".format(Y_test.shape))\n",
    "# The output would be categorical as there are many classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's an 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let'see an random image\n",
    "index=34\n",
    "plt.imshow(X_train[index,:])\n",
    "print(\"It's an {}\".format(Y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's standarize the input with 0 mean\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "lb=LabelBinarizer()\n",
    "Y_train=lb.fit_transform(Y_train)\n",
    "Y_test=lb.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 1/100\n",
      " 64/972 [>.............................] - ETA: 3:55 - loss: 3.5128 - acc: 0.2188WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.356307). Check your callbacks.\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.6473 - acc: 0.3906\n",
      "Epoch 00001: val_acc improved from -inf to 0.18519, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 48s 49ms/step - loss: 2.6247 - acc: 0.3940 - val_loss: 5.3834 - val_acc: 0.1852\n",
      "Epoch 2/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.7315 - acc: 0.7323\n",
      "Epoch 00002: val_acc improved from 0.18519 to 0.20370, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 11s 11ms/step - loss: 0.7275 - acc: 0.7346 - val_loss: 2.0716 - val_acc: 0.2037\n",
      "Epoch 3/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8677\n",
      "Epoch 00003: val_acc did not improve from 0.20370\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.3808 - acc: 0.8663 - val_loss: 2.1084 - val_acc: 0.1759\n",
      "Epoch 4/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.8979\n",
      "Epoch 00004: val_acc improved from 0.20370 to 0.25000, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 11s 11ms/step - loss: 0.2910 - acc: 0.8981 - val_loss: 1.6063 - val_acc: 0.2500\n",
      "Epoch 5/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9583\n",
      "Epoch 00005: val_acc improved from 0.25000 to 0.25000, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.1503 - acc: 0.9588 - val_loss: 1.9750 - val_acc: 0.2500\n",
      "Epoch 6/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9708\n",
      "Epoch 00006: val_acc improved from 0.25000 to 0.56481, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.0941 - acc: 0.9712 - val_loss: 1.3577 - val_acc: 0.5648\n",
      "Epoch 7/100\n",
      " 32/972 [..............................] - ETA: 15s - loss: 0.0614 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.295970). Check your callbacks.\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9875\n",
      "Epoch 00007: val_acc did not improve from 0.56481\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0658 - acc: 0.9877 - val_loss: 1.4965 - val_acc: 0.4815\n",
      "Epoch 8/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9958\n",
      "Epoch 00008: val_acc did not improve from 0.56481\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0350 - acc: 0.9949 - val_loss: 1.5621 - val_acc: 0.4444\n",
      "Epoch 9/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9969\n",
      "Epoch 00009: val_acc did not improve from 0.56481\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0283 - acc: 0.9969 - val_loss: 1.3042 - val_acc: 0.5278\n",
      "Epoch 10/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 00010: val_acc did not improve from 0.56481\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.2060 - val_acc: 0.5278\n",
      "Epoch 11/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 00011: val_acc improved from 0.56481 to 0.63889, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9380 - val_acc: 0.6389\n",
      "Epoch 12/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 00012: val_acc did not improve from 0.63889\n",
      "972/972 [==============================] - 10s 11ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.9032 - val_acc: 0.6111\n",
      "Epoch 13/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 00013: val_acc improved from 0.63889 to 0.66667, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.6667\n",
      "Epoch 14/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 00014: val_acc improved from 0.66667 to 0.85185, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.8519\n",
      "Epoch 15/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 00015: val_acc did not improve from 0.85185\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.3292 - val_acc: 0.8519\n",
      "Epoch 16/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 00016: val_acc improved from 0.85185 to 0.87963, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2781 - val_acc: 0.8796\n",
      "Epoch 17/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 00017: val_acc improved from 0.87963 to 0.95370, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1747 - val_acc: 0.9537\n",
      "Epoch 18/100\n",
      " 32/972 [..............................] - ETA: 13s - loss: 0.0033 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.232462). Check your callbacks.\n",
      " 64/972 [>.............................] - ETA: 14s - loss: 0.0026 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.299188). Check your callbacks.\n",
      " 96/972 [=>............................] - ETA: 14s - loss: 0.0024 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.353080). Check your callbacks.\n",
      "128/972 [==>...........................] - ETA: 14s - loss: 0.0024 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.330090). Check your callbacks.\n",
      "160/972 [===>..........................] - ETA: 13s - loss: 0.0021 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.332069). Check your callbacks.\n",
      "192/972 [====>.........................] - ETA: 13s - loss: 0.0020 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.319584). Check your callbacks.\n",
      "224/972 [=====>........................] - ETA: 12s - loss: 0.0020 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.332069). Check your callbacks.\n",
      "256/972 [======>.......................] - ETA: 12s - loss: 0.0020 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.319584). Check your callbacks.\n",
      "288/972 [=======>......................] - ETA: 11s - loss: 0.0019 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.307099). Check your callbacks.\n",
      "320/972 [========>.....................] - ETA: 10s - loss: 0.0019 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.305175). Check your callbacks.\n",
      "352/972 [=========>....................] - ETA: 9s - loss: 0.0019 - acc: 1.0000 WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.305175). Check your callbacks.\n",
      "384/972 [==========>...................] - ETA: 9s - loss: 0.0018 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.282173). Check your callbacks.\n",
      "416/972 [===========>..................] - ETA: 8s - loss: 0.0017 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.282173). Check your callbacks.\n",
      "448/972 [============>.................] - ETA: 8s - loss: 0.0018 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.282173). Check your callbacks.\n",
      "480/972 [=============>................] - ETA: 7s - loss: 0.0018 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.282173). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/972 [==============>...............] - ETA: 7s - loss: 0.0019 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.266483). Check your callbacks.\n",
      "544/972 [===============>..............] - ETA: 6s - loss: 0.0020 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.248611). Check your callbacks.\n",
      "576/972 [================>.............] - ETA: 6s - loss: 0.0020 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.222058). Check your callbacks.\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.95370\n",
      "972/972 [==============================] - 13s 13ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9352\n",
      "Epoch 19/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.95370\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.9352\n",
      "Epoch 20/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.95370\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9444\n",
      "Epoch 21/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 00021: val_acc did not improve from 0.95370\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9537\n",
      "Epoch 22/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 00022: val_acc did not improve from 0.95370\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9444\n",
      "Epoch 23/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 00023: val_acc did not improve from 0.95370\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1189 - val_acc: 0.9444\n",
      "Epoch 24/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 00024: val_acc improved from 0.95370 to 0.98148, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0958 - val_acc: 0.9815\n",
      "Epoch 25/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 00025: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9815\n",
      "Epoch 26/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 9.7616e-04 - acc: 1.0000\n",
      "Epoch 00026: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 9.7595e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9815\n",
      "Epoch 27/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.8114e-04 - acc: 1.0000\n",
      "Epoch 00027: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 8.9209e-04 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 0.9815\n",
      "Epoch 28/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.0755e-04 - acc: 1.0000\n",
      "Epoch 00028: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 8.0932e-04 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9815\n",
      "Epoch 29/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.5057e-04 - acc: 1.0000\n",
      "Epoch 00029: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 8.5279e-04 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9815\n",
      "Epoch 30/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.9517e-04 - acc: 1.0000\n",
      "Epoch 00030: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 6.9181e-04 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9815\n",
      "Epoch 31/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.5495e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.172284). Check your callbacks.\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 11s 11ms/step - loss: 6.5301e-04 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9815\n",
      "Epoch 32/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.3852e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.181299). Check your callbacks.\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 13s 13ms/step - loss: 6.3660e-04 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9722\n",
      "Epoch 33/100\n",
      " 32/972 [..............................] - ETA: 15s - loss: 4.3401e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.292391). Check your callbacks.\n",
      " 64/972 [>.............................] - ETA: 13s - loss: 4.4384e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.268479). Check your callbacks.\n",
      " 96/972 [=>............................] - ETA: 12s - loss: 5.2603e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.244566). Check your callbacks.\n",
      "128/972 [==>...........................] - ETA: 12s - loss: 5.2281e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.225785). Check your callbacks.\n",
      "160/972 [===>..........................] - ETA: 11s - loss: 4.7934e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.244566). Check your callbacks.\n",
      "192/972 [====>.........................] - ETA: 11s - loss: 4.6731e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.225785). Check your callbacks.\n",
      "224/972 [=====>........................] - ETA: 10s - loss: 4.8857e-04 - acc: 1.0000WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.207004). Check your callbacks.\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.8405e-04 - acc: 1.0000\n",
      "Epoch 00033: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 10s 11ms/step - loss: 5.8471e-04 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9815\n",
      "Epoch 34/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.3136e-04 - acc: 1.0000\n",
      "Epoch 00034: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 6.4494e-04 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9815\n",
      "Epoch 35/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.9894e-04 - acc: 1.0000\n",
      "Epoch 00035: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 6.0380e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9815\n",
      "Epoch 36/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.6609e-04 - acc: 1.0000\n",
      "Epoch 00036: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 5.6381e-04 - acc: 1.0000 - val_loss: 0.0921 - val_acc: 0.9722\n",
      "Epoch 37/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 4.6723e-04 - acc: 1.0000\n",
      "Epoch 00037: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 4.6972e-04 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9815\n",
      "Epoch 38/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 4.6948e-04 - acc: 1.0000\n",
      "Epoch 00038: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 4.6744e-04 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9815\n",
      "Epoch 39/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 4.0072e-04 - acc: 1.0000\n",
      "Epoch 00039: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 4.0454e-04 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9815\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/972 [============================>.] - ETA: 0s - loss: 4.5853e-04 - acc: 1.0000\n",
      "Epoch 00040: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 4.5561e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9815\n",
      "Epoch 41/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 3.7859e-04 - acc: 1.0000\n",
      "Epoch 00041: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 3.7945e-04 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9815\n",
      "Epoch 42/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 3.5996e-04 - acc: 1.0000\n",
      "Epoch 00042: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 3.5809e-04 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9815\n",
      "Epoch 43/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 3.2830e-04 - acc: 1.0000\n",
      "Epoch 00043: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 3.2810e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9815\n",
      "Epoch 44/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 3.2342e-04 - acc: 1.0000\n",
      "Epoch 00044: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 3.2320e-04 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9815\n",
      "Epoch 45/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 3.0569e-04 - acc: 1.0000\n",
      "Epoch 00045: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 3.0415e-04 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9815\n",
      "Epoch 46/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.7753e-04 - acc: 1.0000\n",
      "Epoch 00046: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 2.7860e-04 - acc: 1.0000 - val_loss: 0.0895 - val_acc: 0.9815\n",
      "Epoch 47/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.9367e-04 - acc: 1.0000\n",
      "Epoch 00047: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 2.9281e-04 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9815\n",
      "Epoch 48/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.6637e-04 - acc: 1.0000\n",
      "Epoch 00048: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 2.6809e-04 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9815\n",
      "Epoch 49/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.6726e-04 - acc: 1.0000\n",
      "Epoch 00049: val_acc did not improve from 0.98148\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 2.6881e-04 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9815\n",
      "Epoch 50/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.5604e-04 - acc: 1.0000\n",
      "Epoch 00050: val_acc improved from 0.98148 to 0.99074, saving model to OptimizedModel.hdf5\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 2.5593e-04 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9907\n",
      "Epoch 51/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.5281e-04 - acc: 1.0000\n",
      "Epoch 00051: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 2.5226e-04 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9815\n",
      "Epoch 52/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.2910e-04 - acc: 1.0000\n",
      "Epoch 00052: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 2.2880e-04 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 0.9815\n",
      "Epoch 53/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.1495e-04 - acc: 1.0000\n",
      "Epoch 00053: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 2.1824e-04 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9815\n",
      "Epoch 54/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.0996e-04 - acc: 1.0000\n",
      "Epoch 00054: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 2.0959e-04 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 0.9815\n",
      "Epoch 55/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 2.0744e-04 - acc: 1.0000\n",
      "Epoch 00055: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 2.0702e-04 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9815\n",
      "Epoch 56/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.9998e-04 - acc: 1.0000\n",
      "Epoch 00056: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 2.0166e-04 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 0.9815\n",
      "Epoch 57/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.7869e-04 - acc: 1.0000\n",
      "Epoch 00057: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.7891e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9815\n",
      "Epoch 58/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.6843e-04 - acc: 1.0000\n",
      "Epoch 00058: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.6813e-04 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9815\n",
      "Epoch 59/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.6909e-04 - acc: 1.0000\n",
      "Epoch 00059: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.6989e-04 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9815\n",
      "Epoch 60/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.5850e-04 - acc: 1.0000\n",
      "Epoch 00060: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.6011e-04 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9815\n",
      "Epoch 61/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.6372e-04 - acc: 1.0000\n",
      "Epoch 00061: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.6315e-04 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 0.9815\n",
      "Epoch 62/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.4800e-04 - acc: 1.0000\n",
      "Epoch 00062: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.4676e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9815\n",
      "Epoch 63/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.5307e-04 - acc: 1.0000\n",
      "Epoch 00063: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.5304e-04 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 0.9815\n",
      "Epoch 64/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.4865e-04 - acc: 1.0000\n",
      "Epoch 00064: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.5034e-04 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9815\n",
      "Epoch 65/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.4425e-04 - acc: 1.0000\n",
      "Epoch 00065: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 1.4381e-04 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9815\n",
      "Epoch 66/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.4217e-04 - acc: 1.0000\n",
      "Epoch 00066: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.4228e-04 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9815\n",
      "Epoch 67/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.2831e-04 - acc: 1.0000\n",
      "Epoch 00067: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.2794e-04 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9815\n",
      "Epoch 68/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.1950e-04 - acc: 1.0000\n",
      "Epoch 00068: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.2083e-04 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9815\n",
      "Epoch 69/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.2742e-04 - acc: 1.0000\n",
      "Epoch 00069: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.2645e-04 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9815\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/972 [============================>.] - ETA: 0s - loss: 1.3157e-04 - acc: 1.0000\n",
      "Epoch 00070: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 1.3073e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9815\n",
      "Epoch 71/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.0639e-04 - acc: 1.0000\n",
      "Epoch 00071: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.0780e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9815\n",
      "Epoch 72/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.1741e-04 - acc: 1.0000\n",
      "Epoch 00072: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 1.1736e-04 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9815\n",
      "Epoch 73/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.0931e-04 - acc: 1.0000\n",
      "Epoch 00073: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.0888e-04 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9815\n",
      "Epoch 74/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.0869e-04 - acc: 1.0000\n",
      "Epoch 00074: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.0772e-04 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9815\n",
      "Epoch 75/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.6438e-04 - acc: 1.0000\n",
      "Epoch 00075: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 1.6630e-04 - acc: 1.0000 - val_loss: 0.1900 - val_acc: 0.9722\n",
      "Epoch 76/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.1792e-04 - acc: 1.0000\n",
      "Epoch 00076: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 1.1921e-04 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9815\n",
      "Epoch 77/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 9.5362e-05 - acc: 1.0000\n",
      "Epoch 00077: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 9.7327e-05 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.9907\n",
      "Epoch 78/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.7062e-05 - acc: 1.0000\n",
      "Epoch 00078: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 8.7353e-05 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9815\n",
      "Epoch 79/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.2572e-05 - acc: 1.0000\n",
      "Epoch 00079: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 8.3357e-05 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 0.9815\n",
      "Epoch 80/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.1438e-05 - acc: 1.0000\n",
      "Epoch 00080: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 8.1207e-05 - acc: 1.0000 - val_loss: 0.0871 - val_acc: 0.9815\n",
      "Epoch 81/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 7.8542e-05 - acc: 1.0000\n",
      "Epoch 00081: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 8.8604e-05 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9907\n",
      "Epoch 82/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 1.0467e-04 - acc: 1.0000\n",
      "Epoch 00082: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 1.0756e-04 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9815\n",
      "Epoch 83/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.6721e-05 - acc: 1.0000\n",
      "Epoch 00083: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 8.6243e-05 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9815\n",
      "Epoch 84/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 8.0686e-05 - acc: 1.0000\n",
      "Epoch 00084: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 8.1352e-05 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9815\n",
      "Epoch 85/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 7.2217e-05 - acc: 1.0000\n",
      "Epoch 00085: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 7.2622e-05 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 0.9815\n",
      "Epoch 86/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.7863e-05 - acc: 1.0000\n",
      "Epoch 00086: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 6.9372e-05 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9815\n",
      "Epoch 87/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.9697e-05 - acc: 1.0000\n",
      "Epoch 00087: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 6.9853e-05 - acc: 1.0000 - val_loss: 0.1193 - val_acc: 0.9815\n",
      "Epoch 88/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.6227e-05 - acc: 1.0000\n",
      "Epoch 00088: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 6.6365e-05 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 0.9815\n",
      "Epoch 89/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.4897e-05 - acc: 1.0000\n",
      "Epoch 00089: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 6.4969e-05 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9815\n",
      "Epoch 90/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.5969e-05 - acc: 1.0000\n",
      "Epoch 00090: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 6.5929e-05 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9815\n",
      "Epoch 91/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.9428e-05 - acc: 1.0000\n",
      "Epoch 00091: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 6.9639e-05 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9815\n",
      "Epoch 92/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.9870e-05 - acc: 1.0000\n",
      "Epoch 00092: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 5.9458e-05 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9815\n",
      "Epoch 93/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 6.0537e-05 - acc: 1.0000\n",
      "Epoch 00093: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 6.0395e-05 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9815\n",
      "Epoch 94/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.8432e-05 - acc: 1.0000\n",
      "Epoch 00094: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 5.9290e-05 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9815\n",
      "Epoch 95/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.7530e-05 - acc: 1.0000\n",
      "Epoch 00095: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 5.7129e-05 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9815\n",
      "Epoch 96/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.1242e-05 - acc: 1.0000\n",
      "Epoch 00096: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 5.3454e-05 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9815\n",
      "Epoch 97/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 5.6053e-05 - acc: 1.0000\n",
      "Epoch 00097: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 9ms/step - loss: 5.6502e-05 - acc: 1.0000 - val_loss: 0.0780 - val_acc: 0.9815\n",
      "Epoch 98/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 4.9039e-05 - acc: 1.0000\n",
      "Epoch 00098: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 5.0948e-05 - acc: 1.0000 - val_loss: 0.0793 - val_acc: 0.9815\n",
      "Epoch 99/100\n",
      "960/972 [============================>.] - ETA: 0s - loss: 4.7759e-05 - acc: 1.0000\n",
      "Epoch 00099: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 4.7854e-05 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 0.9815\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/972 [============================>.] - ETA: 0s - loss: 4.8478e-05 - acc: 1.0000\n",
      "Epoch 00100: val_acc did not improve from 0.99074\n",
      "972/972 [==============================] - 8s 8ms/step - loss: 4.9667e-05 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9815\n"
     ]
    }
   ],
   "source": [
    "#Starting with our model\n",
    "ishape=X_train.shape[1:]\n",
    "conv_layers=[3]\n",
    "dense_layers=[1]\n",
    "filters=[64]\n",
    "modelnum=0\n",
    "for conv_layer in conv_layers:\n",
    "    for dense_layer in dense_layers:\n",
    "        for fltr in filters:\n",
    "            NAME=\"Model with {} filters, {} dense layers and {} convolutional layers @ {} time - {}\".format(fltr,dense_layer,conv_layer,int(time.time()),modelnum)\n",
    "            tensorboard=TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            #Defining The Model\n",
    "            model=Sequential()\n",
    "            model.add(InputLayer(ishape))\n",
    "            #The number of convolutional layers\n",
    "            model.add(ZeroPadding2D(padding=(3,3)))\n",
    "            model.add(Conv2D(filters=fltr,kernel_size=(7,7)))\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPool2D(pool_size=(2,2)))\n",
    "            for c in range(conv_layer-1):\n",
    "                model.add(ZeroPadding2D(padding=(3,3)))\n",
    "                model.add(Conv2D(filters=fltr,kernel_size=(7,7)))\n",
    "                model.add(BatchNormalization(axis=3))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPool2D(pool_size=(2,2)))\n",
    "            model.add(Flatten())\n",
    "            for d in range(dense_layer-1):    \n",
    "                model.add(Dense(fltr,activation=\"relu\"))\n",
    "            model.add(Dense(6,activation=\"softmax\"))\n",
    "            filepath=\"OptimizedModel.hdf5\".format(modelnum)\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint,tensorboard]\n",
    "            model.compile(optimizer=\"adam\",metrics=[\"accuracy\"],loss=\"categorical_crossentropy\")\n",
    "            modelnum=modelnum+1\n",
    "            model.fit(X_train,Y_train,epochs=100,validation_split=0.1,shuffle=True,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03585876033951839, 0.9833333333333333]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"Model with epoch 2.hdf5\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_216 (ZeroPadd (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_216 (Conv2D)          (None, 64, 64, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_216 (MaxPoolin (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_217 (ZeroPadd (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_217 (Conv2D)          (None, 32, 32, 64)        200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_217 (MaxPoolin (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_218 (ZeroPadd (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_218 (Conv2D)          (None, 16, 16, 64)        200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_218 (MaxPoolin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 436,358\n",
      "Trainable params: 435,974\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
