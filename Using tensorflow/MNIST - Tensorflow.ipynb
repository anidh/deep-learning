{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "#importing the necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "tf.set_random_seed(0)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will download the mnist dataset through tensorflow itt will be split between mnist.test and mmnist.train containing about\n",
    "#10k and 50k images each\n",
    "def load_dataset(flatten=False):\n",
    "    \"\"\"mnist = tf.keras.datasets.mnist\n",
    "    (X_train, Y_train),(X_test, Y_test) = mnist.load_data()\n",
    "    X_train, X_test = X_train / 255.0,X_test / 255.0\n",
    "    if flatten:\n",
    "        X_train=X_train.reshape([X_train.shape[0],-1])\n",
    "        X_test=X_test.reshape([X_test.shape[0],-1])\n",
    "    return X_train, Y_train,X_test, Y_test\"\"\"\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "    # split, reshape, shuffle\n",
    "    m = 60000\n",
    "    m_test = X.shape[0] - m\n",
    "    X_train, X_test = X[:m], X[m:]\n",
    "    Y_train, Y_test = y[:m], y[m:]\n",
    "    return X_train, Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-x-x-x-x-x-x-x-x-x-x-x-x-x-x--x-x-xPrinting the shapes-x-x-x-x-x-x-x-x-x-x-x-x--x-x\n",
      "The training shape of X is (60000, 784) and Y is (60000,)\n",
      "The testing shape of X is (10000, 784) and Y is (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_dataset()\n",
    "print(\"-x-x-x-x-x-x-x-x-x-x-x-x-x-x--x-x-xPrinting the shapes-x-x-x-x-x-x-x-x-x-x-x-x--x-x\")\n",
    "print(\"The training shape of X is {} and Y is {}\".format(X_train.shape, Y_train.shape))\n",
    "print(\"The testing shape of X is {} and Y is {}\".format(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels dimension:\n",
      "(60000, 10)\n",
      "Test labels dimension:\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb=LabelBinarizer()\n",
    "Y_train=lb.fit_transform(Y_train)\n",
    "Y_test=lb.transform(Y_test)\n",
    "print('Train labels dimension:');print(Y_train.shape)\n",
    "print('Test labels dimension:');print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#designing the placeholders for the X and the Y\n",
    "def placholder(n_x,n_y,keep_prob):\n",
    "    #update 1 adding the learning rate decay function\n",
    "    X=tf.placeholder(tf.float32,shape=[None,n_x],name=\"X\")\n",
    "    Y=tf.placeholder(tf.float32,shape=[None,n_y],name=\"Y\")\n",
    "    keep_prob=tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    return X,Y,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =Tensor(\"X:0\", shape=(?, 784), dtype=float32)\n",
      "Y =Tensor(\"Y:0\", shape=(?, 10), dtype=float32)\n",
      "Dropout Probability =Tensor(\"keep_prob:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X,Y,keep_prob=placholder(784,10,0.75)\n",
    "print(\"X =\" +str(X))\n",
    "print(\"Y =\" +str(Y))\n",
    "print(\"Dropout Probability =\" +str(keep_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now initialzing the weights which are present\n",
    "def initialize_params():\n",
    "    W1=tf.get_variable(\"W1\",[784,200],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b1=tf.get_variable(\"b1\",[200],initializer=tf.zeros_initializer(),dtype=tf.float32)\n",
    "    W2=tf.get_variable(\"W2\",[200,100],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b2=tf.get_variable(\"b2\",[100],initializer=tf.zeros_initializer(),dtype=tf.float32)\n",
    "    W3=tf.get_variable(\"W3\",[100,70],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b3=tf.get_variable(\"b3\",[70],initializer=tf.zeros_initializer(),dtype=tf.float32)\n",
    "    W4=tf.get_variable(\"W4\",[70,40],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b4=tf.get_variable(\"b4\",[40],initializer=tf.zeros_initializer(),dtype=tf.float32)\n",
    "    W5=tf.get_variable(\"W5\",[40,10],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b5=tf.get_variable(\"b5\",[10],initializer=tf.zeros_initializer(),dtype=tf.float32)\n",
    "    \n",
    "    parameters={\"W1\":W1,\"b1\":b1,\"W2\":W2,\"b2\":b2,\"W3\":W3,\"b3\":b3,\"W4\":W4,\"b4\":b4,\"W5\":W5,\"b5\":b5}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(784, 200) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(200,) dtype=float32_ref>\n",
      ".........\n",
      "W5 = <tf.Variable 'W5:0' shape=(40, 10) dtype=float32_ref>\n",
      "b5 = <tf.Variable 'b5:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X,Y,keep_prob=placholder(784,10,0.75) \n",
    "parameters=initialize_params()\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\".........\")\n",
    "print(\"W5 = \" + str(parameters[\"W5\"]))\n",
    "print(\"b5 = \" + str(parameters[\"b5\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X,parameters,keep_prob):\n",
    "    cache={}\n",
    "    Z1=tf.add((tf.matmul(X,parameters[\"W1\"])),parameters[\"b1\"])\n",
    "    A1=tf.nn.relu(Z1)\n",
    "    A1d=tf.nn.dropout(A1,keep_prob)\n",
    "    Z2=tf.add((tf.matmul(A1d,parameters[\"W2\"])),parameters[\"b2\"])\n",
    "    A2=tf.nn.relu(Z2)\n",
    "    A2d=tf.nn.dropout(A2,keep_prob)\n",
    "    Z3=tf.add((tf.matmul(A2d,parameters[\"W3\"])),parameters[\"b3\"])\n",
    "    A3=tf.nn.relu(Z3)\n",
    "    #A3d=tf.nn.dropout(A3,keep_prob)\n",
    "    Z4=tf.add((tf.matmul(A3,parameters[\"W4\"])),parameters[\"b4\"])\n",
    "    A4=tf.nn.relu(Z4)\n",
    "    #A4d=tf.nn.dropout(A4,keep_prob)\n",
    "    Z5=tf.add((tf.matmul(A4,parameters[\"W5\"])),parameters[\"b5\"])\n",
    "    \n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_4:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,Y,keep_prob=placholder(784,10,0.75)\n",
    "    parameters=initialize_params()\n",
    "    Z5=feed_forward(X,parameters,keep_prob)\n",
    "print(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_tf(Z5,Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\" \n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5,labels=Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,Y,keep_prob=placholder(784,10,0.75)\n",
    "    parameters=initialize_params()\n",
    "    Z5=feed_forward(X,parameters,keep_prob)\n",
    "    cost=compute_cost_tf(Z5,Y)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y,seed, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    #The Code is Transformed for m,n_x Case#\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:]\n",
    "    shuffled_Y = Y[permutation,:].reshape((m,Y.shape[1]))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X_train,Y_train,X_test,Y_test,learning_rate,num_epochs,dropout_prob,mini_batch_size=64,print_cost=True):\n",
    "    #initializing the shapes\n",
    "    print(X_train.shape)\n",
    "    (m,n_x)=X_train.shape\n",
    "    (n_y)=Y_train.shape[1]\n",
    "    seed=3\n",
    "    ops.reset_default_graph()\n",
    "    costs=[]\n",
    "    #Initializing all the placeholders\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    X,Y,keep_prob=placholder(n_x,n_y,dropout_prob)\n",
    "\n",
    "    #Now the weights initialization\n",
    "    parameters=initialize_params()\n",
    "    \n",
    "    #The forward propagation\n",
    "    Z5=feed_forward(X,parameters,keep_prob)\n",
    "    \n",
    "    #The cost which we have got\n",
    "    cost=compute_cost_tf(Z5,Y)\n",
    "    \n",
    "    #The learning rate decay parameter\n",
    "    lr = tf.train.exponential_decay(learning_rate, global_step,decay_steps=2000,decay_rate=0.96, staircase=True)\n",
    "    \n",
    "    #Defining the optimizer\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=lr,beta1=0.98,beta2=0.999,epsilon=1e-08,name=\"Adam\").minimize(cost,global_step)\n",
    "    \n",
    "    #The variable initialization part\n",
    "    init=tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        print(\"----------------Initialized--------------------------\")\n",
    "        print(\"The algorithm will be run for {} epochs\".format(num_epochs))\n",
    "        for epoch in range(num_epochs+1):\n",
    "            epoch_cost=0\n",
    "            num_of_mini_batches=int(m/mini_batch_size)\n",
    "            seed=seed+1\n",
    "            minibatches = random_mini_batches(X_train, Y_train,seed,mini_batch_size = 64)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _,minibatchcost=sess.run([optimizer,cost],feed_dict={X: minibatch_X,Y: minibatch_Y,keep_prob:dropout_prob})\n",
    "                epoch_cost+=minibatchcost/num_of_mini_batches\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"The cost for Epoch {} is {} with dropout probability {}\".format(epoch, epoch_cost,dropout_prob))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "        print(\"---------------------------ModelTrained-----------------------\")\n",
    "        \n",
    "        print(\"The Cost vs Iteration curve is -\")\n",
    "        \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\" Initial Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Saving The Parameters!------\")\n",
    "        \n",
    "        parameters=sess.run(parameters)        \n",
    "        correct_prediction = tf.equal(tf.argmax(Z5,1), tf.argmax(Y,1))\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train,keep_prob:dropout_prob}))\n",
    "        print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test,keep_prob:1.0}))\n",
    "\n",
    "        return parameters\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "----------------Initialized--------------------------\n",
      "The algorithm will be run for 1000 epochs\n",
      "The cost for Epoch 0 is 1.8286672783508608 with dropout probability 0.75\n",
      "The cost for Epoch 100 is 0.05642353098104256 with dropout probability 0.75\n",
      "The cost for Epoch 200 is 0.03891341548144427 with dropout probability 0.75\n",
      "The cost for Epoch 300 is 0.03622848109522061 with dropout probability 0.75\n",
      "The cost for Epoch 400 is 0.03550568100566245 with dropout probability 0.75\n",
      "The cost for Epoch 500 is 0.03821263351882897 with dropout probability 0.75\n",
      "The cost for Epoch 600 is 0.03677115611563778 with dropout probability 0.75\n",
      "The cost for Epoch 700 is 0.03298245175793044 with dropout probability 0.75\n",
      "The cost for Epoch 800 is 0.03560356515198305 with dropout probability 0.75\n",
      "The cost for Epoch 900 is 0.03447889452522473 with dropout probability 0.75\n",
      "The cost for Epoch 1000 is 0.035629318209829446 with dropout probability 0.75\n",
      "---------------------------ModelTrained-----------------------\n",
      "The Cost vs Iteration curve is -\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving The Parameters!------\n",
      "Train Accuracy: 0.99093336\n",
      "Test Accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "parameters=nn_model(X_train,Y_train,X_test,Y_test,learning_rate=0.003,num_epochs=1000,dropout_prob=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
